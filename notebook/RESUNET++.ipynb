{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import glob \n",
    "\n",
    "\n",
    "WORKING_DIR = '/home/ntphat/projects/medico/medico'\n",
    "os.chdir(WORKING_DIR)\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "coco_annot = osp.join(DATA_DIR, 'coco_annotation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKPOINT_PATH: ''\n",
      "DATA:\n",
      "  ROOT_DIR: ./data\n",
      "  TRAIN: train.csv\n",
      "  TRAIN_IMAGES: images\n",
      "  TRAIN_MASKS: dfs_masks\n",
      "  VAL: val.csv\n",
      "INFERENCE:\n",
      "  BATCH_SIZE: 10\n",
      "  MASK_THRES: 0.5\n",
      "  SAVE_DIR: ./result/resunet++\n",
      "MODEL:\n",
      "  IMAGE_SIZE:\n",
      "  - 512\n",
      "  - 512\n",
      "  NAME: res_unet_plus\n",
      "OUTPUT_DIR: ./result/resunet++\n",
      "SOLVER:\n",
      "  BATCH_SIZE: 2\n",
      "  EARLY_STOPPING: 10\n",
      "  EPOCH: 100\n",
      "  LOGGING_STEP: 10\n",
      "  LR: 0.001\n",
      "  VALIDATION_EVERY: -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", (UserWarning, FutureWarning))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import model.ResUnet.dataset as dataset\n",
    "from model.ResUnet.core.res_unet import ResUnet\n",
    "from model.ResUnet.core.res_unet_plus import ResUnetPlusPlus\n",
    "from model.ResUnet.utils import (\n",
    "    get_parser,\n",
    "    get_default_config,\n",
    "    BCEDiceLoss,\n",
    "    MetricTracker,\n",
    "    jaccard_index,\n",
    "    dice_coeff,\n",
    "    MyWriter,\n",
    "    metrics,\n",
    ")\n",
    "from model.ResUnet.init_config import setup\n",
    "\n",
    "def draw_mask(image, mask, save_path=None):\n",
    "    mask = mask.squeeze(2)\n",
    "    mask[mask < 0.5] = 0.0\n",
    "#     y, x = np.nonzero(mask)\n",
    "    image[np.nonzero(mask)] = (0,255,0)\n",
    "    if save_path is not None:\n",
    "        pil_img = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "        pil_img.save(save_path)\n",
    "#         cv2.imwrite(save_path, image)\n",
    "    return image\n",
    "\n",
    "\n",
    "checkpoint_dir = osp.join(WORKING_DIR, 'result/resunet++/checkpoints')\n",
    "cfg = get_default_config()\n",
    "cfg.merge_from_file('src/model/ResUnet/configs/default_resunet.yaml')\n",
    "\n",
    "str_cfg = cfg.dump()\n",
    "print(str_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED MODEL SUCCESSFULLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 1)\n",
      "[[<AxesSubplot:> <AxesSubplot:>]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<AxesSubplot:> <AxesSubplot:>]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 512x512 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 512x512 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_dir = osp.join(WORKING_DIR, 'result/resunet++/checkpoints')\n",
    "cfg = get_default_config()\n",
    "cfg.merge_from_file('src/model/ResUnet/configs/default_resunet.yaml')\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "# Create val dataset:\n",
    "val_dataset = dataset.ImageDataset(\n",
    "    cfg, False, transform=transforms.Compose([dataset.ToTensorTarget()])\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, num_workers=4, shuffle=False\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "model = ResUnetPlusPlus(3).cuda()\n",
    "resume = osp.join(checkpoint_dir, 'best_model.pt')\n",
    "checkpoint = torch.load(resume)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(f\"LOADED MODEL SUCCESSFULLY\")\n",
    "\n",
    "from model.ResUnet.utils.visualize import visualize_result\n",
    "# do inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, data in tqdm(enumerate(val_dataloader)):\n",
    "        inputs = data['sat_img'].cuda()\n",
    "        labels = data['map_img'].cuda()\n",
    "        img_paths = data['image_path']\n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        all_scores = metrics.calculate_all_metrics(outputs, labels)\n",
    "        img_names = [p.strip().split('/')[-1] for p in img_paths]\n",
    "        save_paths = [osp.join('.', p) for p in img_names]\n",
    "        \n",
    "        imgs = inputs.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        gts = labels.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        preds = outputs.cpu().squeeze(0).permute(0, 2, 3, 1).numpy()\n",
    "        \n",
    "        print(preds[0].shape)\n",
    "        visualize_result(imgs, gts, preds, save_paths, all_scores, cfg)\n",
    "        \n",
    "#         gt_path = f'src/model/ResUnet/gt.jpg'\n",
    "#         pred_path = f'src/model/ResUnet/pred.jpg'\n",
    "#         draw_mask(img, gt, gt_path)\n",
    "#         draw_mask(img, pred, pred_path)        \n",
    "        \n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(1.0)\n",
    "b = max(a, torch.tensor(2.0))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d17475865483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
